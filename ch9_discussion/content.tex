

%Recent technological advancements in profiling single cells are having significant repercussions in many fields of biology. Profiling thousands of individual cells in a genome-wide manner provides opportunities to study cell heterogeneity and dynamics, for example inferring mechanisms for cellular development or intercellular communication. 
%Hundreds of new software tools were developed \cite{zappia_exploringsinglecellrnaseq_2018} to perform these new types of analyses, or to fit existing analytical tools to deal with new data characteristics (e.g. differential expression, dimensionality reduction, normalisation). 
%
%One major shortcoming during the advent of single cell omics was that majority of the newly developed computational tools were not quantitatively and comparatively evaluated. Rather, they relied on anecdotal evidence to demonstrate its usefulness. This issue is not the result of the tool developer's malevolence, but instead of the lack of data required to perform such comprehensive benchmarks.
%
%Uncontrolled development of software tools without comprehensive benchmarking poses serious problems. 
%For one, it slows down scientific progress. Every end-user needs to make a large commitment researching the domain in order to make an informed decision of which tool to use, or risk a higher incidence of false positive discoveries (either way, valuable resources are being wasted). It also negatively impacts the credibility of the field and discourages new users. 
%
%In this work, we aim to speed up scientific progress in single-cell omics by providing end-users with guidelines on how to use which state-of-the-art tools, and by providing developers with the necessary tools to assert a mimimum performance criterion when introducing new methods.
%
%We develop benchmarking strategies for assessing the performance of novel computational tools constrained by low availability of real data (Chapter~\ref{chap:dyngen}). \textit{In silico} simulations of individual cells are used to help kick-start emerging domains much more safely and allow anticipation of future technological developments by already developing computational tools.
%
%We apply this strategy to perform a comparison of TI methods (Chapter~\ref{chap:dynbenchmark}). Trajectory inference is one of the largest categories of all the novel single-cell omics tools, yet a comprehensive and quantitative study of the advantages and disadvantages of the numerous tools was hitherto lacking. 
%
%We introduce a novel TI method specialised in inferring linear trajectories (Chapter~\ref{chap:scorpius}).
%Despite linear TI being the most simple but commonly used form of trajectory inference, the benchmark demonstrated that most TI methods are not capable of producing accurate models of linear datasets.
%
%We conclude by inventing a new type of approach aimed at inferring the GRN of individual cells (Chapter~\ref{chap:bred}).
%Due a lack of real data which can be used as a gold standard dataset, we use \textit{in silico} single-cell data to quantitatively evaluate the performance.
%

% * Single cell omics is expanding at rates faster than any single mind can try to conceive
%Pioneers developing revolutionary tools to process new types of data are typically faced with the problem on how to quantitatively evaluate the accuracy of their approach. After all, the amount of data required to perform a comprehensive evaluation of their tool does not yet exist and is too expensive to generate at the time. 


%In the computational jungle of single-cell omics, experts act as beacons of hope by sharing guidelines based on comprehensive benchmarking studies. Their disseminations (in the form of manuscripts \cite{lafzi_tutorialguidelinesexperimental_2018,luecken_currentbestpractices_2019}, courses \cite{kiselev_analysissinglecell_2019,martens_analysissinglecell_2019}, and slides shown during keynote caffeine refuelling sessions \cite{hemberg_coffeebreakanalysis_2019}) are crucial in leading new users, and ultimately the whole field, to better practices for performing single-cell omics analyses.

%Before embarking on this perilous adventure, I attempt to write a "Hippocratic oath for bioinformaticians", to guide me through this dissertation and not stray from the path of righteousness.
%
%\subsection{Hippocratic oath for bioinformaticians}
%We proceed with caution in developing new tools. Its results should not only be convincing and easy to interpret, but also accurate, robust, and reproducible. We open source. Our software should work reliably and fail gracefully when it does not. We acknowledge that writing automated tests is dull but necessary for maintaining long-term software projects. % TODO: improve

%Computer scientists should proceed with caution in developing new software, however, as the results produced should not only be convincing and easy to interpret, but the software should be robust and generate sufficiently accurate models of the underlying system.
%
%Bit too excited -- false positives, poor accuracy, scalability issues, poor software quality. 

\section{dyngen discussion}
% felt that upon the development of a new technologies, good quality control practices from
% other technologies were not being carried over because the data required to evaluate computational
% tools does not exist yet and is too expensive to develop.

\section{dynbenchmark discussion}
\begin{itemize}
	\item Already outdated when the manuscript was published online
	\item Update benchmark with more TI methods, newer (and larger) datasets, perform parameter optimisation on methods
	\item Include RNA velocity as inputs
\end{itemize}

\section{SCORPIUS discussion}
\begin{itemize}
	\item Extension to inferring non-linear trajectories, i.e. with principal graphs
\end{itemize}

\section{bred discussion}

\section{incgraph discussion}

\section{dyno discussion}

