\section*{Introduction}
Even the simplest of living organisms already consist of complex biochemical networks which must be able to respond to a variety of stressful conditions in order to survive. 
An organism can be characterised using numerous interaction networks, including gene regulation, metabolic, signalling, and protein-protein interaction. 
The advent of high-throughput profiling methods (e.g. microarrays and RNA sequencing) have allowed to observe the molecular contents of a cell, which in turn have enabled computational network inference methods to reverse engineer the biochemical interaction networks~ \cite{albert_networkinferenceanalysis_2007}.
Improving the accuracy of inferred networks has been a long-standing challenge, but the development of ever more sophisticated algorithms and community-wide benchmarking studies have resulted in significant process~ \cite{marbach_revealingstrengthsweaknesses_2010, narendra_comprehensiveassessmentmethods_2011, marbach_wisdomcrowdsrobust_2012, aijo_biophysicallymotivatedregulatory_2017}. 

Several recent developments involve incorporating topological priors, either to guide the inference process~ \cite{lopes_featureselectiontechnique_2014} or post-process the network~ \cite{ruyssinck_netterrerankinggene_2016}.
A common prior is that biological networks are highly modular~ \cite{rives_modularorganizationcellular_2003}, as they consist of multiple collections of functionally or physically linked molecules~ \cite{hartwell_molecularmodularcell_1999,barabasi_networkbiologyunderstanding_2004}. At the lowest level, each module is made up out of biochemical interactions arranged in small topological patterns, which act as fundamental building blocks~ \cite{milo_networkmotifssimple_2002}.

Graphlets~ \cite{przulj_modelinginteractomescalefree_2004} are one of the tools which could be used to add a topological prior to a biological network,
Graphlets are small connected subnetworks which can be counted to identify which low-level topological patterns are present in a network. By comparing how topologically similar a predicted network is to what would be expected of a true biological network, a predicted network can be optimised in order to obtain a better topology. 

By counting the number of occurrences of each of the different graphlets (Fig~\ref{fig_graphlets}A) touching a specific node, one can characterise the topology surrounding it. The graphlet counts of a network can be represented as a matrix with one row for each of the nodes and one column for each of the graphets (Fig~\ref{fig_graphlets}B). 
An orbit represents a class of isomorphic (i.e. resulting in the same structure) positions of nodes within a graphlet (Fig \ref{fig_graphlets}A, coloured in red).
Both graphlets and orbits have been used extensively for predicting the properties of nodes such as protein functionality~ \cite{milenkovic_uncoveringbiologicalnetwork_2008,guerrero_characterizationproteasomeinteraction_2008,singh_graphletsignaturebasedscoring_2014} and gene oncogenicity~ \cite{milenkovic_optimalnetworkalignment_2010}, by performing network alignment~ \cite{kuchaiev_topologicalnetworkalignment_2010,milenkovic_globalnetworkalignment_2013} or using them as a similarity measure in machine learning tasks~ \cite{shervashidze_efficientgraphletkernels_2009,vacic_graphletkernelsprediction_2010}. 

%% FIGURE 1
\picfig{fig/figure1.pdf}{\LARGEfigure}{fig_graphlets}{{\bf Graphlet counting in a network characterises its local topologies.}
	(A) In total, there are 30 different graphlets containing 2 to 5 nodes, ranging from $G_0$ to $G_{29}$. Orbits are an extension of graphlets which also take into account the position of a node within a graphlet. The 73 different orbits are coloured in red. (B) By counting the occurrences of these graphlets in the network, the local topology surrounding a node can be quantified.}

In this work, we focus on optimising gene regulatory networks by incorporating a topological prior as part of a topology optimisation process. We seek to optimise a predicted network by iteratively modifying the network and accepting modifications that lead to topological properties that resemble better those of true biological networks.

However, using graphlets to perform topology optimisation was hitherto not possible. Calculating the graphlet counts using the most state-of-the-art graphlet counting of a moderately sized gene regulatory network already has an execution time of about five seconds (\textit{E. coli}, $\sim 3000$ genes, $\sim 10000$ interactions, up to graphlets up to 5 nodes).
While this computational time poses no issue for regular static networks, recalculating all graphlet counts for every network modification made as part of a topology optimisation is computationally intractable. For example, performing 100'000 iterations of topology optimisation on a similarly sized network and calculating the topological impact of 10 possible edge modification at each iteration, already results in a computational time of about 12 days. Graphlet-based topology optimisation thus quickly becomes infeasible for larger networks.

When adding or removing an edge to a large network, the number of altered graphlets is much smaller than the total number of graphlets in the network. It could therefore be much more efficient to iterate over and count all the graphlets that have been added or removed as a result of the edge modification, than it is to recalculate the graphlet counts from scratch. 

Eppstein et al. introduced data structures and algorithms for updating the counts of size-three \cite{eppstein_hindexgraphits_2009} and size-four \cite{eppstein_extendeddynamicsubgraph_2012} subgraphs in a dynamic setting. The data structures were determined such that the amortised time is $O(h)$ and $O(h^2)$, respectively, where $h$ is the h-index of the network \cite{hirsch_indexquantifyindividual_2005}.

We developed IncGraph, an alternative algorithm and implementation for performing incremental counting of graphlets up to size five. We show empirically that IncGraph is several orders of magnitude faster at calculating the differences in graphlet counts in comparison to non-incremental counting approaches. In addition, we demonstrate the practical applicability by developing a graphlet-based optimisation criterion for biological networks.


\section*{Materials and methods}
Assume a network $G$ of which the graphlet counts $C_G$ are known. $C_G$ is an $n$-by-$m$ matrix, with $n$ the number of vertices in the network, $m = 73$ is the number of different orbits, and where $C_G[i,j]$ is the number of times node $i$ is part of a graphlet at orbit $O_j$. 
Further assume that one edge has either been added or removed from $G$, resulting in $G'$, at which point the counts $C_{G'}$ need to be observed. If multiple edges have been modified, the method described below can be repeated for each edge individually.

\subsection*{Incremental graphlet counting}
As stated earlier, recalculating the graphlet counts for each modification made to the network quickly becomes computationally intractable for larger network sizes. However, as the differences in topology between $G$ and $G'$ are small, it is instead possible to calculate the differences in graphlet counts $\Delta_{G, G'}$ instead. This is much more efficient to calculate, as only the neighbourhood of the modified edges needs to be explored. $C_{G'}$ can thus be calculated as $C_{G'} = C_G + \Delta_{G,G'}$.


The differences in graphlet counts $\Delta_{G, G'}$ are calculated by iterating recursively over the neighbours surrounding each of the modified edges (Fig~\ref{code_incgraph}). Several strategies are used in order to calculate $\Delta_{G,G'}$ as efficiently as possible (Fig~\ref{fig_efficient}).
(A) The delta matrix is calculated separately for each modified edge. Since the edge already contains two out of five nodes and any modified graphlet is a connected subgraph, the neighbourhood of this edge only needs to be explored up to depth 3 in order to iterate over all modified graphlets. 
(B) We propose a lookup table to look up the graphlet index of each node of a given subgraph. By weighting each possible edge in a 5-node graphlet, the sum of the edges of a subgraph can be used to easily look up the corresponding graphlet index.
(C) During the recursive iteration of the neighbourhood, the same combination of nodes is never visited twice.
(D) As the network can be relatively large, the adjacency matrix is binary compressed in order to save memory. One integer requires 4 bytes and contains the adjacency boolean values of 32 edges, whereas otherwise 32 booleans would require 32 bytes. For example, 1GB of memory is large enough to store a compressed adjacency matrix of 92681 nodes. If the network contains too many nodes to fit a compressed adjacency matrix into the memory, a list of sets containing each node's neighbours is used instead.


%% FIGURE 2
\picfig{fig/figure2.pdf}{\LARGEfigure}{fig_efficient}{{\bf Several strategies are employed in order to reduce time and memory consumption.}
(A) Only the depth 3 neighbourhood of each modified edge needs to be explored in order to have visited all modified five-node graphlets. (B) A lookup table can be used to easily look up the graphlet index of a subgraph, by weighing each edge in a 5-node subgraph by a power of~2. (C) The same combination of five nodes is never repeated, as to avoid counting the same graphlet multiple times. (D) The adjacency matrix of the network is compressed in order to reduce memory usage.}


IncGraph supports counting graphlets and orbits of subgraphs up to five nodes in undirected networks. By modifying the lookup table, the method can be easily extended to directed graphlets or larger-node graphlets, or limited to only a selection of graphlets. This allows for variations of the typical graphlets to be studied in an incremental setting.

\subsection*{Timing experiments}
We compared the execution time needed to calculate the graphlet counts in iteratively modified networks between our method and a state-of-the-art non-incremental algorithm, Orca~ \cite{hocevar_combinatorialapproachgraphlet_2014}. Orca is a heavily optimised algorithm for counting 5-node graphlets in static networks, and outperforms all other static graphlet counting algorithms by an order of magnitude~ \cite{hocevar_combinatorialapproachgraphlet_2014}.

The timing experiments were performed by generating networks from 3 different network models, making modifications to those networks while still adhering to the network model, and measuring the execution times taken for both approaches to calculate the new graphlet counts (Fig~\ref{fig_method_speedup}). 

%% FIGURE 3
\picfig{fig/figure3.pdf}{\LARGEfigure}{fig_method_speedup}{{\bf Static network model generators were modified to generate dynamic networks.}
	Three network models were used: Barabási–Albert, Erdős–Rényi, and Geometric. Step 0: a network is generated according to the network model and the given parameters. Step 1: the network is modified such that the result is as likely to have been generated by the network model. Step 2: The time for IncGraph to calculate the differences in graphlet counts is measured ($T_{IG}$). Step 3: The time for the non-incremental approach to calculate the graphlet counts of the new network is measured ($T_{NI}$). Steps 1 to 3 are repeated until all modifications generated at step 0 are processed, or until an execution time threshold has been reached.}


The network models were based on three static network models: Barab\'asi-Albert~ \cite{albert_statisticalmechanicscomplex_2002}, Erd\H{o}s--R\'enyi~ \cite{erdos_randomgraphs_1959}, and Geometric~ \cite{appel_minimumvertexdegree_1997}. These models were adapted to generate evolving networks instead (Figs~\ref{code_ba}, \ref{code_er}, and \ref{code_geo}).
Each model generates an initial network according to the static network model it is based on, and a list of network modifications (removing an edge from or adding an edge to the network). These network modifications are made such that at any given time point in the evolving network, it is likely that the network at its current state could have been generated by the original static network model.

Networks were generated with varying network models, between 1000 and 16000 nodes, node degrees between 2 and 64, and 10000 time points. We measured the time needed to calculate the delta matrix at random time points until 1 hour has passed. All timings experiments were carried out on Intel(R) Xeon(R) CPU E5-2665 $@$ 2.40GHz processors, with one thread per processor.
The generation of networks with higher node counts or degrees was constrained by the execution time of the network generators, not by IncGraph. All data and scripts are made available at \href{https://github.com/rcannood/incgraph-scripts}{github.com/rcannood/incgraph-scripts}.

\subsection*{Gene regulatory network optimisation experiments}
We demonstrate the usefulness of IncGraph by using a simple graphlet-based metric to optimise gene regulatory networks. 
One of the striking differences between real and predicted gene regulatory networks is that the predicted networks contain highly connected subnetworks, which contain high amounts of false positives.
We determine a penalty score such that predicted networks containing graphlets with many redundant edges will be penalised in comparison to very sparse networks. 

The \textit{redundancy penalty} (Fig~\ref{fig_method_reranking}A) of a network is defined as the sum of occurrences of each graphlet multiplied by the redundancy associated with each individual graphlet. The redundancy of a graphlet is the number of edges that can be removed without disconnecting the nodes from one another.
By using the redundancy penalty score, we aim to improve the gene regulatory network (Fig~\ref{fig_method_reranking}B). 

The topology optimisation procedure uses an empty network as initialisation and grows the network by selecting interactions iteratively. Each iteration, the top $k = 100$ highest ranked interactions that are not currently part of the network are evaluated, and the highest ranked interaction passing the redundancy criterion is selected (Fig~\ref{fig_method_reranking}C). This procedure is repeated until a predefined amount of time has passed.
As the aim of this experiment is not to obtain the highest performing topology optimisation method, parameter optimisation of $k$  has not been performed and is considered to be outside the scope of this work.


%% FIGURE 4
\picfig{fig/figure4.pdf}{\hugefigure}{fig_method_reranking}{{\bf Predicted gene regulatory networks of model organisms are optimised to reduce the false positive rate.}
	A)~The number of redundant edges in each graphlet are counted. B) The network is optimised in order to obtain a lower redundancy over time. Two networks are shown, one before and one after the optimisation procedure. Edges coloured in red have been removed from the network after optimisation, green edges have been added. C) Starting from an empty network, the interactions are modified by iteratively evaluating the increase in redundancy of the next $k$ interactions, and adding the first edge for which its redundancy is less than the $90^\textrm{th}$ percentile redundancy.}


We optimised gene regulatory networks of \textit{E. coli} and \textit{S. cerevisiae}. The predicted networks were generated using the network inference method GENIE3~ \cite{huynh-thu_inferringregulatorynetworks_2010} with default parameters. Gene expression data was obtained from COLOMBOS~ \cite{moretto_colombosv3leveraging_2016} and GEO~ \cite{edgar_geneexpressionomnibus_2002}, respectively. The predicted networks and the optimised versions thereof were compared against respective lists of known gene regulatory interactions~ \cite{gama-castro_regulondbversionhighlevel_2016,ma_denovolearninggenomescale_2014}.

% Results and Discussion can be combined.
\section*{Results and discussion}
The contributions of this work are twofold. Firstly, we propose a new method for incrementally calculating the differences in graphlet counts in changing graphs, and show that it is orders of magnitude faster than non-incremental approaches. Secondly, we demonstrate its applicability by optimising a predicted gene regulatory network in order to reduce the false positive rate therein.

\subsection*{Execution time is reduced by orders of magnitude}
Timing experiments show that IncGraph is significantly faster in calculating the delta matrix in comparison to calculating the graphlet counts from scratch at each iteration (Fig~\ref{fig_speedup}). The observed speedup ratios between IncGraph and the non-incremental approach Orca ranges from about 50$\times$ to 10000$\times$. The speedup ratio increases as the network size increases. For larger networks, IncGraph can thus calculate the delta matrices of 10000 edge modifications while the non-incremental approach calculates one graphlet count matrix.

Surprisingly, IncGraph obtains higher execution times for networks with 5657 nodes than for networks with 8000 nodes. One possible explanation is that the size of the data structures containing those networks are particularly favourable in avoiding cache misses. Confirmation of this explanation, however, would require further investigation.

%% FIGURE 5
\picfig{fig/figure5.pdf}{\LARGEfigure}{fig_speedup}{{\bf IncGraph is significantly faster than non-incremental approaches.}
	For small networks, the execution time of IncGraph $T_{IG}$ is already 50 times less than that of non-incremental approaches $T_{NI}$. This ratio increases even further for networks with higher numbers of nodes or higher average degrees.}


Comparing the execution time of IncGraph to the h-index of the networks indicates that the amortised time of IncGraph could be $O(h^3)$ (Fig~\ref{sfig_hindex}). This is in line with the amortised times $O(h)$ and $O(h^2)$ of the algorithm described by Eppstein et al. \cite{eppstein_extendeddynamicsubgraph_2012} for counting three-size and four-size subgraphs respectively.

\subsection*{IncGraph allows for better regulatory network optimisation}
We implemented a graphlet-based optimisation algorithm for improving the false positive rate of the predicted gene regulatory networks of \textit{E. coli} and \textit{S. cerevisiae}. After reranking the regulatory interactions, the F1 score of the first 1000~interactions had increased by 7.6\% and 2.2\% respectively (Fig~\ref{fig_reranking}A). The obtained speedup of about 15-30$\times$ (Fig~\ref{fig_reranking}B) is in line with the experiments on \textit{in silico} networks.
Namely, for the \textit{E. coli} network at 9618~interactions and 889~nodes (average degree~=~10.8), a speedup of about 30$\times$ was obtained.
Similarly, for the \textit{S. cerevisiae} network at 8013~interactions and 1254~nodes (average degree~=~6.4), a speedup of about 15$\times$ was obtained.
These speedups are in the same order of magnitude of similarly sized networks (1000~nodes and 8000~interactions) generated with a Barab\'asi-Albert model, with a speedup of 65$\times$. This is to be expected, as such networks share the same scale-free property that gene regulatory networks have.


%% FIGURE 6
\picfig{fig/figure6.png}{\Largefigure}{fig_reranking}{{\bf A simple graphlet-based scoring method improves predicted regulatory networks.}
	(A) The F1 score was calculated by calculating the harmonic mean of the AUROC and AUPR scores of the first 1000 interactions. (B) IncGraph is significantly faster than the non-incremental approach. Note that for each interaction added to the network, the graphlet counts of 100 putative interactions were evaluated.}

\section*{Conclusion}
Many improvements over the past few years have resulted in efficient graphlet counting algorithms, even for large static networks. However, needing to perform the simplest of tasks tens of thousands of times quickly becomes computationally intractable. As such, recalculating the graphlet counts of a network after each of the many network modification is infeasible.

This study introduces a method for calculating the differences in graphlet (and orbit) counts, which we call incremental graphlet counting or IncGraph for short. We show that IncGraph is at least 10-100 times faster than non-incremental methods for networks of moderate size, and that the speedup ratio increases even further for larger networks. 
To demonstrate the applicability of IncGraph, we optimised a predicted gene regulatory network by enumerating over the ranked edges and observing the graphlet counts of several candidate edges before deciding which edge to add to the network.

IncGraph enables graphlet-based metrics to characterize online networks, e.g. in order to track certain network patterns over time, as a similarity measure in a machine learning task, or as a criterion in a topology optimisation.


\section{Supporting information}

\newcommand{\pluseq}{\mathrel{+}=}
\newcommand{\asteq}{\mathrel{*}=}

\begin{figure}[htb!]
	\centering
	\includegraphics[width=.8\linewidth]{fig/figureS1.pdf} 
	\caption{
		\textbf{Empirical measurements show a strong relation between the execution time of IncGraph and the h-index cubed of the network it was applied to.} This is in line with the findings by Eppstein et al., where counting 3-size subgraphs has an amortised time of $O(h)$ and counting 4-size subgraphs has an amortised time of $O(h^2)$.
	}
	\label{sfig_hindex}
\end{figure}

\begin{figure}[htb!]
	\begin{algorithmic}
		\Function{CalculateDelta}{Network $G'$, Node $n_0$, Node $n_1$}
		\State \Comment{Assuming an edge $(n_0, n_1)$ has just been added or removed from $G'$}
		\State $\Delta^- \gets \Call{Matrix}{\Call{NumNodes}{G}, 73}$ \Comment{For storing the orbit counts of the removed graphlets}
		\State $\Delta^+ \gets \Call{Matrix}{\Call{NumNodes}{G}, 73}$ \Comment{For storing the orbit counts of the added graphlets}
		\State $B_0 = \{n_0, n_1\}$ \Comment{A blacklist of nodes not to visit anymore}
		\State $e = (n_0, n_1)$ \Comment{Different name for the edge}
		\If{$e \in N'$}
		\State $(m^-, m^+) = (0, 1)$ \Comment{In other words, $m^- = 1$ iff $e \in N$ and $m^+ = 1$ iff $e \in N'$}
		\Else
		\State $(m^-, m^+) = (1, 0)$
		\EndIf
		\State $x_0 = 0$
		\State $(\Delta^+, \Delta^-) = \Call{CountOrbits}{\Delta^+, \Delta^-, (n_0, n_1), x_0, m^-, m^+}$ \Comment{Update delta matrices for current nodes}
		
		%\For{$n_2 \in \Call{Neighbours}{S_0}$}
		\For{$n_2 \in \bigcup_{i \in \{0, 1\}}\Call{Neighbours}{n_i}$}
		\If{$n_2 \not\in B_0$}
		\State $B_0 = \{n_2\} \bigcup B_0$ \Comment{Add $n_2$ to blacklist $B_0$}
		\State $x_1 = x_0 + \Call{W}{G', (n_0, n_2), 1} + \Call{W}{G', (n_1, n_2), 2}$ \Comment{Calculate edge weights for current nodes}
		\State $(\Delta^+, \Delta^-) = \Call{CountOrbits}{\Delta^+, \Delta^-, (n_0, n_1, n_2), x_1, m^-, m^+}$
		\State $B_1 = B_0$ \Comment{Make a copy for the next iteration depth}
		\For{$n_3 \in \bigcup_{i \in \{0, 1, 2\}}\Call{Neighbours}{n_i}$}
		\If{$n_3 \not\in B_1$}
		\State $B_1 = \{n_3\} \bigcup B_1$
		\State $x_2 = x_1 + \Call{W}{G', (n_0, n_3), 3} + \Call{W}{G', (n_1, n_3), 4} + \Call{W}{G', (n_2, n_3), 5}$
		\State $(\Delta^+, \Delta^-) = \Call{CountOrbits}{\Delta^+, \Delta^-, (n_0, n_1, n_2, n_3), x_2, m^-, m^+}$
		\State $B_2 = B_1$
		
		\For{$n_4 \in \bigcup_{i \in \{0, 1, 2, 3\}}\Call{Neighbours}{n_i}$}
		\If{$n_4 \not\in B_2$}
		\State $B_2 = \{n_4\} \bigcup B_2$
		\State $x_3 = x_2 + \Sigma_{i \in \{0, 1, 2, 3\}}\Call{W}{G', (n_i, n_4), i+6}$
		\State $(\Delta^+, \Delta^-) = \Call{CountOrbits}{\Delta^+, \Delta^-, (n_0, n_1, n_2, n_3, n_4), x_3, m^-, m^+}$
		\EndIf
		\EndFor
		\EndIf
		\EndFor
		\EndIf
		\EndFor
		\EndFunction
		\Function{CountOrbits}{$\Delta^+$, $\Delta^-$, Nodes $S$, Edgeweights $x$, Modifier $m^-$, Modifier $m^+$}
		\State $L^- = L[x + m^-]$ \Comment{Look up the orbits of the subgraph induced by $S$ in $N$}
		\State $\Delta^-[S, L^-] \pluseq 1$ \Comment{Increment orbit counts of nodes $S$ at positions $L^-$ in $\Delta^-$}
		\State $L^+ = L[x + m^+]$ \Comment{Look up the orbits of the subgraph induced by $S$ in $N'$}
		\State $\Delta^+[S, L^+] \pluseq 1$ \Comment{Increment orbit counts of nodes $S$ at positions $L^+$ in $\Delta^+$}
		\State \Return $(\Delta^-, \Delta^+)$
		\EndFunction
		\Function{W}{Network $G$, Edge $e$, Exponent $i$}
		\State \Return $e \in \Call{Edges}{G} \ ?\  2^i : 0$ \Comment{Return $2^i$ if $G$ contains edge $e$}
		\EndFunction
	\end{algorithmic}
	\caption{
		\textbf{Pseudocode of IncGraph.} IncGraph calculates $\Delta_{G,G'}$ using a strict branch-and-bound strategy.
	}
	\label{code_incgraph}
\end{figure}

\begin{figure}[htb!]	
	\begin{algorithmic}
		\Function{BarabasiAlbert}{number of nodes $n$, degree $d$, \par\hspace*{3.72cm} number of operations $o$, offset exponent $x=1$}
		\State $D \gets \Call{Rep}{0, n}$ \Comment{All nodes start with 0 degree}
		\State $T \gets \Call{Rep}{\{\}, n}$ \Comment{List of targets of each node}
		\State $S \gets \Call{Rep}{\{\}, n}$ \Comment{List of sources of each node}
		\State $O \gets (\,)$ \Comment{Variable to store the generated operations in}
		
		\Procedure{AddEdge}{node $i$, node $j$, add as operation $b$}
		\State $D[i] \gets D[i] + 1$;\ $D[j] \gets D[j] + 1$ \Comment{Update degrees}
		\State $T[i] \gets T[i] \cup \{j\}$;\ $S[j] \gets S[j] \cup \{i\}$ \Comment{Update targets and sources}
		\If{$b$}
		\State $O \gets O + (\textrm{ADD}, (i, j))$
		\EndIf
		\EndProcedure
		\Procedure{RemoveEdge}{node $i$, node $j$, add as operation $b$}
		\State $D[i] \gets D[i] - 1$;\ $D[j] \gets D[j] - 1$ \Comment{Update degrees}
		\State $T[i] \gets T[i] \setminus \{j\}$;\ $S[j] \gets S[j] \setminus \{i\}$ \Comment{Update targets and sources}
		\If{$b$}
		\State $O \gets O + (\textrm{REM}, (i, j))$
		\EndIf
		\EndProcedure
		\Procedure{AddNode}{node $i$, add as operations $b$}
		\State $C \gets \{j \,|\, 0 \leq j < i \wedge j \not\in S[i]\}$ \Comment{Select candidate neighbours}
		\State $W \gets (D[C] \,/\, \Sigma D[C])^x$ \Comment{Calculate weights for preferred attachment}
		\State $X \gets $ sample $d$ neighbours from $C$ with weights $W$
		\For{$j \in X$}
		\State \Call{AddEdge}{$i$, $j$, $b$}
		\EndFor
		\EndProcedure
		\Procedure{RemoveNode}{node $i$, add as operations $b$}
		\While{$|T[i]| > 0$}
		\State $j \gets \Call{Head}{T[i], 1}$
		\State \Call{RemoveEdge}{$i$, $j$, $b$}
		\EndWhile
		\EndProcedure
		\For{$i \in \{1 \,..\, m\}$}
		\For{$j \in \{0 \,..\, i-1\}$}
		\State \Call{AddEdge}{$i$, $j$, false} \Comment{Start with $m+1$ complete graph}
		\EndFor
		\EndFor
		\For{$i \in \{m+1\,..\,n-1\}$}
		\State \Call{AddNode}{$i$, false} \Comment{Add the rest of the nodes}
		\EndFor
		\State $G_0 \gets \{ (i, j) \,|\, i \in \{0\,..\,n-1\} \wedge j \in N[i]\}$ \Comment{Initial network}
		\While{$|O| < o$} \Comment{Modify network until $O$ is sufficiently large}
		\State $i \gets$ Sample 1 index from $\{0 \,..\, n-1\}$
		\State \Call{RemoveNode}{$i$, true}
		\State \Call{AddNode}{$i$, true}
		\EndWhile
		\State $O \gets \Call{Head}{O, o}$ 
		\State \Return $(N_0, O)$ \Comment{Return the initial network and $o$ operations}
		\EndFunction
	\end{algorithmic}
	\caption{
		\textbf{Pseudo code for generating an evolving Barab\'asi-Albert (BA) network.} It first generates a BA network, and then generates $o$ operations such that at any time point, the network is or very closely resembles a BA network.
	}
	\label{code_ba}
\end{figure}


\begin{figure}[htb!]
	\begin{algorithmic}
		\Function{ErdosRenyi}{number of nodes $n$, number of edges $e$, number of operations $o$}
		\State $P \gets \{(i, j) \,|\, i \in \{1 \,..\, n-1\} \wedge j \in \{0 \,..\, i-1\}\}$ \Comment{All possible interactions}
		\State $N_0 \gets$ Sample $e$ edges from $P$
		\State $N_c \gets N_0$
		\While{$|O|<o$}
		\State $e_a \gets $ Sample 1 edge from $P \setminus N_c$
		\State $e_r \gets $ Sample 1 edge from $N_c$
		\State $N_c \gets (N_c \setminus e_r) \cup \{e_a\}$
		\State $O \gets O + ((\textrm{ADD}, e_a), (\textrm{REM}, e_r))$
		\EndWhile
		\State $O \gets \Call{Head}{O, o}$ 
		\State \Return $(N_0, O)$ \Comment{Return the initial geometric network and $o$ operations}
		\EndFunction
	\end{algorithmic}
	\caption{
		\textbf{Pseudo code for generating an evolving Erd\H{o}s--R\'enyi (ER) network.} It first generates an ER network, and then generates $o$ operations such that at any time point, the network is or very closely resembles an ER network.
	}
	\label{code_er}
\end{figure}

\begin{figure}[htb!]
	\begin{algorithmic}
		\Function{Geometric}{number of nodes $n$, number of edges $e$, \par\hspace*{2.77cm} number of operations $o$, number of dimensions $d=3$}
		\State $P \gets$ Sample $n$ points from a multivariate continuous uniform distribution $U_{d}((0,1)^{d})$
		\State $D \gets$ Calculate distance matrix from $P$
		\State $N_0 \gets \Call{Head}{\Call{ArgSort}{\Call{LowerTriangle}{D}}, e}$ \Comment{Initial network}
		\State $N_p \gets N_0$
		\State $O \gets (\,)$ \Comment{Variable to store the generated operations in}
		\While{$|O| < o$} \Comment{Modify network until $O$ is sufficiently large}
		\State $i \gets $ Sample 1 index from $\{0\,..\,n-1\}$
		\State $P[i] \gets$ Sample 1 point from a $U_{d}((0,1)^{d})$ \Comment{Give node $i$ a new location}
		\State $D[i,] \gets D[,i] \gets $ Calculate new distances between node $i$ and all other nodes
		\State $N_c \gets \Call{Head}{\Call{ArgSort}{\Call{LowerTriangle}{D}}, e}$ \Comment{New network}
		\State $O_a \gets \{(\textrm{ADD}, e) \,|\, e \not\in E(N_p) \wedge e \in E(N_c) \}$ \Comment{Gather added edges}
		\State $O_r \gets \{(\textrm{REM}, e) \,|\, e \in E(N_p) \wedge e \not\in E(N_c) \}$ \Comment{Gather removed edges}
		\State $O \gets O + \Call{Shuffle}{O_a + O_r}$ \Comment{Append new operations to $O$}
		\State $N_p \gets N_c$
		\EndWhile
		\State $O \gets \Call{Head}{O, o}$ 
		\State \Return $(N_0, O)$ \Comment{Return the initial geometric network and $o$ operations}
		\EndFunction
	\end{algorithmic}
	\caption{
		\textbf{Pseudo code for generating an evolving geometric network.} It first generates a geometric network, and then generates $o$ operations such that at any time point, the network is or very closely resembles a geometric network.
	}
	\label{code_geo}
\end{figure}


\clearpage
\section{References}
\printbibliography[heading=none]